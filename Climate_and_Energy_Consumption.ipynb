{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2oHzbMyMl-Rk"
      },
      "outputs": [],
      "source": [
        "# source: http://kaggle.com/datasets/emirhanakku/climate-and-energy-consumption-dataset-20202024"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data\n",
        "csv_path = '/content/global_climate_energy_2020_2024.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "\n",
        "print(\"1. EDA & DATA CLEANING\")\n",
        "\n",
        "# Data Info\n",
        "print(\"Data Info\")\n",
        "df.info()\n",
        "\n",
        "print(\"Missing Values\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"Statistical Summary\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"Column Names\")\n",
        "print(list(df.columns))\n",
        "\n",
        "# Drop constant columns if they exist\n",
        "if 'country' in df.columns:\n",
        "    df_clean = df.drop(columns=['country'])\n",
        "else:\n",
        "    df_clean = df.copy()\n",
        "\n",
        "# Convert date to datetime\n",
        "df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
        "df_clean = df_clean.set_index('date').sort_index()\n",
        "\n",
        "print(f\"Cleaned DataFrame: {df_clean.shape}\")\n",
        "print(df_clean.head())\n",
        "\n",
        "print(\"2. FEATURE ENGINEERING (NO DATA LEAKAGE)\")\n",
        "\n",
        "# Automatically detect target variable (assuming 'energy_price' or similar)\n",
        "possible_targets = ['energy_price', 'price', 'energy_cost']\n",
        "TARGET = None\n",
        "for col in possible_targets:\n",
        "    if col in df_clean.columns:\n",
        "        TARGET = col\n",
        "        break\n",
        "\n",
        "if TARGET is None:\n",
        "    # If no standard target found, use the last numeric column\n",
        "    TARGET = df_clean.select_dtypes(include=[np.number]).columns[-1]\n",
        "\n",
        "print(f\"\\nTarget variable: {TARGET}\")\n",
        "\n",
        "# Separate features and target BEFORE any transformations\n",
        "X = df_clean.drop(columns=[TARGET])\n",
        "y = df_clean[TARGET]\n",
        "\n",
        "# Get all numeric columns for feature engineering\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nNumeric features available: {numeric_cols}\")\n",
        "\n",
        "# TRAIN/TEST SPLIT (CHRONOLOGICAL FOR TIME SERIES)\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "print(f\"\\nTrain set: {X_train.shape}, Test set: {X_test.shape}\")\n",
        "print(f\"  Train period: {X_train.index[0]} to {X_train.index[-1]}\")\n",
        "print(f\"  Test period: {X_test.index[0]} to {X_test.index[-1]}\")\n",
        "\n",
        "# FEATURE ENGINEERING FUNCTIONS\n",
        "def create_time_features(df):\n",
        "    \"\"\"Create time-based features\"\"\"\n",
        "    df = df.copy()\n",
        "    df['day_of_year'] = df.index.dayofyear\n",
        "    df['month'] = df.index.month\n",
        "    df['day_of_week'] = df.index.dayofweek\n",
        "    df['week_of_year'] = df.index.isocalendar().week\n",
        "    return df\n",
        "\n",
        "def create_lag_features(df, columns, lags=[1, 3, 7]):\n",
        "    \"\"\"Create lag features (NO LEAKAGE - only uses past values)\"\"\"\n",
        "    df = df.copy()\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            for lag in lags:\n",
        "                df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
        "    return df\n",
        "\n",
        "def create_rolling_features(df, columns, windows=[3, 7]):\n",
        "    \"\"\"Create rolling statistics (NO LEAKAGE - only uses past values)\"\"\"\n",
        "    df = df.copy()\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            for window in windows:\n",
        "                df[f'{col}_roll_mean{window}'] = df[col].shift(1).rolling(window=window).mean()\n",
        "                df[f'{col}_roll_std{window}'] = df[col].shift(1).rolling(window=window).std()\n",
        "    return df\n",
        "\n",
        "def create_interaction_features(df, columns):\n",
        "    \"\"\"Create interaction terms between first few columns\"\"\"\n",
        "    df = df.copy()\n",
        "    # Create interactions between first 3 numeric columns if available\n",
        "    if len(columns) >= 2:\n",
        "        df[f'{columns[0]}_{columns[1]}'] = df[columns[0]] * df[columns[1]]\n",
        "    if len(columns) >= 3:\n",
        "        df[f'{columns[0]}_{columns[2]}'] = df[columns[0]] * df[columns[2]]\n",
        "        df[f'{columns[1]}_{columns[2]}'] = df[columns[1]] * df[columns[2]]\n",
        "    return df\n",
        "\n",
        "# Select columns for lag/rolling (use first few numeric columns)\n",
        "lag_cols = numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols\n",
        "rolling_cols = numeric_cols[:2] if len(numeric_cols) >= 2 else numeric_cols\n",
        "\n",
        "# Combine train and test for proper feature engineering\n",
        "X_combined = pd.concat([X_train, X_test])\n",
        "y_combined = pd.concat([y_train, y_test])\n",
        "\n",
        "# Apply all feature engineering to combined data\n",
        "X_combined_fe = create_time_features(X_combined)\n",
        "X_combined_fe = create_lag_features(X_combined_fe, lag_cols)\n",
        "X_combined_fe = create_rolling_features(X_combined_fe, rolling_cols)\n",
        "X_combined_fe = create_interaction_features(X_combined_fe, numeric_cols)\n",
        "\n",
        "# Remove rows with NaN from combined dataset\n",
        "valid_idx = X_combined_fe.notna().all(axis=1)\n",
        "X_combined_clean = X_combined_fe[valid_idx]\n",
        "y_combined_clean = y_combined[valid_idx]\n",
        "\n",
        "print(f\"After NaN removal - Combined: {X_combined_clean.shape}\")\n",
        "\n",
        "# Now split back into train and test using the INDICES\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index\n",
        "\n",
        "# Filter to only valid indices that remain after NaN removal\n",
        "train_valid_indices = train_indices.intersection(X_combined_clean.index)\n",
        "test_valid_indices = test_indices.intersection(X_combined_clean.index)\n",
        "\n",
        "X_train_fe = X_combined_clean.loc[train_valid_indices]\n",
        "y_train = y_combined_clean.loc[train_valid_indices]\n",
        "X_test_fe = X_combined_clean.loc[test_valid_indices]\n",
        "y_test = y_combined_clean.loc[test_valid_indices]\n",
        "\n",
        "print(f\"Final split - Train: {X_train_fe.shape}, Test: {X_test_fe.shape}\")\n",
        "print(f\"  Train period: {X_train_fe.index[0]} to {X_train_fe.index[-1]}\")\n",
        "print(f\"  Test period: {X_test_fe.index[0]} to {X_test_fe.index[-1]}\")\n",
        "print(f\"\\nTotal features created: {X_train_fe.shape[1]}\")\n",
        "\n",
        "# SCALING\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_fe)\n",
        "X_test_scaled = scaler.transform(X_test_fe)\n",
        "\n",
        "print(\"\\nFeatures scaled using StandardScaler\")\n",
        "\n",
        "print(\"3. MODEL TRAINING & EVALUATION\")\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
        "    'Ridge Regression': Ridge(alpha=1.0)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "\n",
        "    # Train\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train_scaled)\n",
        "    y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Metrics\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'test_rmse': test_rmse,\n",
        "        'test_mae': test_mae,\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "    print(f\"  Train R2: {train_r2:.4f}\")\n",
        "    print(f\"  Test R2:  {test_r2:.4f}\")\n",
        "    print(f\"  Test RMSE: {test_rmse:.4f}\")\n",
        "    print(f\"  Test MAE:  {test_mae:.4f}\")\n",
        "\n",
        "# FEATURE IMPORTANCE (Random Forest)\n",
        "print(\"4. FEATURE IMPORTANCE (Top 15)\")\n",
        "\n",
        "rf_model = results['Random Forest']['model']\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train_fe.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(feature_importance.head(15))\n",
        "\n",
        "# SUMMARY\n",
        "print(\"5. MODEL COMPARISON SUMMARY\")\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Train R2': [results[m]['train_r2'] for m in results.keys()],\n",
        "    'Test R2': [results[m]['test_r2'] for m in results.keys()],\n",
        "    'Test RMSE': [results[m]['test_rmse'] for m in results.keys()],\n",
        "    'Test MAE': [results[m]['test_mae'] for m in results.keys()]\n",
        "})\n",
        "\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['test_r2'])\n",
        "print(f\"\\nBest Model: {best_model_name} (Test R2 = {results[best_model_name]['test_r2']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMdAApZGncAV",
        "outputId": "f6337221-a96f-4cbd-a85d-6487456537a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36540, 10)\n",
            "         date  country  avg_temperature  humidity  co2_emission  \\\n",
            "0  2020-01-01  Germany            28.29     31.08        212.63   \n",
            "1  2020-01-02  Germany            28.38     37.94        606.05   \n",
            "2  2020-01-03  Germany            28.74     57.67        268.72   \n",
            "3  2020-01-04  Germany            26.66     51.34        167.32   \n",
            "4  2020-01-05  Germany            26.81     65.38        393.89   \n",
            "\n",
            "   energy_consumption  renewable_share  urban_population  \\\n",
            "0            11348.75            14.42             76.39   \n",
            "1             4166.64             5.63             86.26   \n",
            "2             4503.80            14.20             75.92   \n",
            "3             3259.13            13.84             63.15   \n",
            "4             7023.72             6.93             76.02   \n",
            "\n",
            "   industrial_activity_index  energy_price  \n",
            "0                      51.22         83.93  \n",
            "1                      78.27        110.40  \n",
            "2                      48.96        173.58  \n",
            "3                      97.42         89.13  \n",
            "4                      81.89         40.60  \n",
            "1. EDA & DATA CLEANING\n",
            "Data Info\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 36540 entries, 0 to 36539\n",
            "Data columns (total 10 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   date                       36540 non-null  object \n",
            " 1   country                    36540 non-null  object \n",
            " 2   avg_temperature            36540 non-null  float64\n",
            " 3   humidity                   36540 non-null  float64\n",
            " 4   co2_emission               36540 non-null  float64\n",
            " 5   energy_consumption         36540 non-null  float64\n",
            " 6   renewable_share            36540 non-null  float64\n",
            " 7   urban_population           36540 non-null  float64\n",
            " 8   industrial_activity_index  36540 non-null  float64\n",
            " 9   energy_price               36540 non-null  float64\n",
            "dtypes: float64(8), object(2)\n",
            "memory usage: 2.8+ MB\n",
            "Missing Values\n",
            "date                         0\n",
            "country                      0\n",
            "avg_temperature              0\n",
            "humidity                     0\n",
            "co2_emission                 0\n",
            "energy_consumption           0\n",
            "renewable_share              0\n",
            "urban_population             0\n",
            "industrial_activity_index    0\n",
            "energy_price                 0\n",
            "dtype: int64\n",
            "Statistical Summary\n",
            "       avg_temperature      humidity  co2_emission  energy_consumption  \\\n",
            "count     36540.000000  36540.000000  36540.000000        36540.000000   \n",
            "mean         13.580868     59.971469    445.820452         7295.904857   \n",
            "std          10.077249     17.303103    234.360906         3693.928504   \n",
            "min          -9.600000     30.000000     50.150000         1001.890000   \n",
            "25%           5.630000     45.010000    248.675000         4184.177500   \n",
            "50%          13.790000     59.990000    422.655000         6921.620000   \n",
            "75%          20.840000     74.970000    628.422500        10175.110000   \n",
            "max          38.710000     90.000000    999.850000        15998.050000   \n",
            "\n",
            "       renewable_share  urban_population  industrial_activity_index  \\\n",
            "count     36540.000000      36540.000000               36540.000000   \n",
            "mean         15.944080         74.982156                  70.173094   \n",
            "std           5.334804          8.645400                  17.334816   \n",
            "min           5.000000         60.000000                  40.000000   \n",
            "25%          12.020000         67.470000                  55.300000   \n",
            "50%          15.715000         75.030000                  70.055000   \n",
            "75%          19.840000         82.502500                  85.260000   \n",
            "max          30.870000         90.000000                 100.000000   \n",
            "\n",
            "       energy_price  \n",
            "count  36540.000000  \n",
            "mean     115.279848  \n",
            "std       49.178361  \n",
            "min       30.000000  \n",
            "25%       72.420000  \n",
            "50%      115.240000  \n",
            "75%      158.270000  \n",
            "max      200.000000  \n",
            "Column Names\n",
            "['date', 'country', 'avg_temperature', 'humidity', 'co2_emission', 'energy_consumption', 'renewable_share', 'urban_population', 'industrial_activity_index', 'energy_price']\n",
            "Cleaned DataFrame: (36540, 8)\n",
            "            avg_temperature  humidity  co2_emission  energy_consumption  \\\n",
            "date                                                                      \n",
            "2020-01-01            28.29     31.08        212.63            11348.75   \n",
            "2020-01-01            22.67     69.96        674.21             4239.03   \n",
            "2020-01-01            30.61     55.17        334.08             5592.89   \n",
            "2020-01-01            23.57     80.03        164.82            11560.13   \n",
            "2020-01-01            12.65     81.06        261.87             9749.27   \n",
            "\n",
            "            renewable_share  urban_population  industrial_activity_index  \\\n",
            "date                                                                       \n",
            "2020-01-01            14.42             76.39                      51.22   \n",
            "2020-01-01             9.97             67.81                      43.09   \n",
            "2020-01-01             8.90             61.41                      73.01   \n",
            "2020-01-01            14.29             68.54                      43.86   \n",
            "2020-01-01             7.86             88.20                      47.31   \n",
            "\n",
            "            energy_price  \n",
            "date                      \n",
            "2020-01-01         83.93  \n",
            "2020-01-01         96.68  \n",
            "2020-01-01        106.54  \n",
            "2020-01-01        155.06  \n",
            "2020-01-01        184.10  \n",
            "2. FEATURE ENGINEERING (NO DATA LEAKAGE)\n",
            "\n",
            "Target variable: energy_price\n",
            "\n",
            "Numeric features available: ['avg_temperature', 'humidity', 'co2_emission', 'energy_consumption', 'renewable_share', 'urban_population', 'industrial_activity_index']\n",
            "\n",
            "Train set: (29232, 7), Test set: (7308, 7)\n",
            "  Train period: 2020-01-01 00:00:00 to 2024-01-01 00:00:00\n",
            "  Test period: 2024-01-01 00:00:00 to 2024-12-31 00:00:00\n",
            "After NaN removal - Combined: (36533, 31)\n",
            "Final split - Train: (29233, 31), Test: (7320, 31)\n",
            "  Train period: 2020-01-01 00:00:00 to 2024-01-01 00:00:00\n",
            "  Test period: 2024-01-01 00:00:00 to 2024-12-31 00:00:00\n",
            "\n",
            "Total features created: 31\n",
            "\n",
            "Features scaled using StandardScaler\n",
            "3. MODEL TRAINING & EVALUATION\n",
            "\n",
            "--- Training Random Forest ---\n",
            "  Train R2: 0.0892\n",
            "  Test R2:  -0.0011\n",
            "  Test RMSE: 49.3857\n",
            "  Test MAE:  42.8140\n",
            "\n",
            "--- Training Gradient Boosting ---\n",
            "  Train R2: 0.0895\n",
            "  Test R2:  -0.0112\n",
            "  Test RMSE: 49.6355\n",
            "  Test MAE:  42.9843\n",
            "\n",
            "--- Training Ridge Regression ---\n",
            "  Train R2: 0.0011\n",
            "  Test R2:  -0.0004\n",
            "  Test RMSE: 49.3684\n",
            "  Test MAE:  42.8165\n",
            "4. FEATURE IMPORTANCE (Top 15)\n",
            "                      feature  importance\n",
            "3          energy_consumption    0.045881\n",
            "6   industrial_activity_index    0.044423\n",
            "18          co2_emission_lag3    0.042475\n",
            "23  avg_temperature_roll_std7    0.041906\n",
            "16              humidity_lag7    0.041065\n",
            "19          co2_emission_lag7    0.040188\n",
            "5            urban_population    0.040037\n",
            "13       avg_temperature_lag7    0.039717\n",
            "17          co2_emission_lag1    0.038267\n",
            "4             renewable_share    0.037874\n",
            "27         humidity_roll_std7    0.037182\n",
            "14              humidity_lag1    0.037075\n",
            "15              humidity_lag3    0.036625\n",
            "1                    humidity    0.035512\n",
            "11       avg_temperature_lag1    0.035142\n",
            "5. MODEL COMPARISON SUMMARY\n",
            "            Model  Train R2   Test R2  Test RMSE  Test MAE\n",
            "    Random Forest  0.089237 -0.001096  49.385732 42.814017\n",
            "Gradient Boosting  0.089524 -0.011249  49.635531 42.984279\n",
            " Ridge Regression  0.001114 -0.000395  49.368435 42.816535\n",
            "\n",
            "Best Model: Ridge Regression (Test R2 = -0.0004)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "BEST_MODEL_NAME = 'Ridge Regression'\n",
        "\n",
        "# Retrieve the trained model object\n",
        "BEST_MODEL = results[BEST_MODEL_NAME]['model']\n",
        "\n",
        "# The fitted StandardScaler is still named 'scaler'\n",
        "# The original feature columns are still available from the previous step.\n",
        "\n",
        "# 7. SAVE NECESSARY ARTIFACTS FOR DEPLOYMENT\n",
        "joblib.dump(BEST_MODEL, 'simple_climate_model.joblib')\n",
        "print(f\"Saved Best Model: {BEST_MODEL_NAME}\")\n",
        "\n",
        "joblib.dump(scaler, 'simple_climate_scaler.joblib')\n",
        "print(\"Saved Scaler\")\n",
        "\n",
        "# The original columns used for raw input (before complex features)\n",
        "original_numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "joblib.dump(original_numeric_cols, 'original_numeric_cols.joblib')\n",
        "print(\"Saved Original Numeric Columns\")\n",
        "\n",
        "# The list of final features the model *should* expect (after simple time features)\n",
        "# Re-calculate the list of final features needed for deployment\n",
        "X_original_with_time = X.copy()\n",
        "# NOTE: We need to ensure the index is datetime for the time features to work\n",
        "X_original_with_time.index = pd.to_datetime(X_original_with_time.index)\n",
        "X_original_with_time['day_of_year'] = X_original_with_time.index.dayofyear\n",
        "X_original_with_time['month'] = X_original_with_time.index.month\n",
        "X_original_with_time['day_of_week'] = X_original_with_time.index.dayofweek\n",
        "X_original_with_time['week_of_year'] = X_original_with_time.index.isocalendar().week.astype(int)\n",
        "\n",
        "FINAL_FEATURES_SIMPLE = X_original_with_time.columns.tolist()\n",
        "joblib.dump(FINAL_FEATURES_SIMPLE, 'final_features_simple.joblib')\n",
        "print(\"Saved Final Simple Feature Columns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgDoOljlA3Su",
        "outputId": "3c0bd376-fa92-429f-af88-492cad417d4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Best Model: Ridge Regression\n",
            "Saved Scaler\n",
            "Saved Original Numeric Columns\n",
            "Saved Final Simple Feature Columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load saved artifacts\n",
        "try:\n",
        "    MODEL = joblib.load('simple_climate_model.joblib')\n",
        "    SCALER = joblib.load('simple_climate_scaler.joblib')\n",
        "    ORIGINAL_COLS = joblib.load('original_numeric_cols.joblib')\n",
        "    FINAL_FEATURES = joblib.load('final_features_simple.joblib')\n",
        "    TARGET = 'energy_price' # Assuming this target for display purposes\n",
        "    print(\"Simplified Deployment Artifacts Loaded Successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    # NOTE: This error means you need to run the artifact saving cell above first.\n",
        "    print(f\"Deployment Error: Could not load required file: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# Function to create time features (copied from original notebook)\n",
        "def create_time_features_deploy(input_df, target_date):\n",
        "    \"\"\"Create time-based features\"\"\"\n",
        "    df = input_df.copy()\n",
        "    df.index = [target_date] # Set the index correctly\n",
        "    df['day_of_year'] = df.index.dayofyear\n",
        "    df['month'] = df.index.month\n",
        "    df['day_of_week'] = df.index.dayofweek\n",
        "    df['week_of_year'] = df.index.isocalendar().week.astype(int) # Ensure integer\n",
        "    return df\n",
        "\n",
        "# Prediction function: Simple inputs only\n",
        "def predict_climate_simple(target_date_str, *raw_inputs):\n",
        "    \"\"\"\n",
        "    Predicts the target variable using the simplified model.\n",
        "    Inputs: target_date_str, followed by the values of all ORIGINAL_COLS.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        target_date = datetime.strptime(target_date_str, '%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        return \"Error: Invalid date format. Please use YYYY-MM-DD.\"\n",
        "\n",
        "    # 1. Create a DataFrame from the raw inputs\n",
        "    input_data = pd.DataFrame(\n",
        "        {col: [val] for col, val in zip(ORIGINAL_COLS, raw_inputs)}\n",
        "    )\n",
        "\n",
        "    # 2. Add time features\n",
        "    input_data_fe = create_time_features_deploy(input_data.copy(), target_date)\n",
        "\n",
        "    # 3. Align features (Crucial step)\n",
        "    X_predict = input_data_fe[FINAL_FEATURES]\n",
        "\n",
        "    # 4. Scale the features (using the pre-fitted scaler)\n",
        "    scaled_features = SCALER.transform(X_predict)\n",
        "\n",
        "    # 5. Predict\n",
        "    prediction = MODEL.predict(scaled_features)[0]\n",
        "\n",
        "    # 6. Return formatted result\n",
        "    return f\"Predicted {TARGET.replace('_', ' ').title()} for {target_date_str}: **{prediction:,.4f}**\"\n",
        "\n",
        "# Dynamically generate the list of inputs for Gradio (Only the raw features + date)\n",
        "input_components = [\n",
        "    gr.Textbox(label=\"Target Date (YYYY-MM-DD)\", value=datetime.now().strftime('%Y-%m-%d'))\n",
        "]\n",
        "\n",
        "# Add inputs for the numeric features of the TARGET DAY\n",
        "for col in ORIGINAL_COLS:\n",
        "    input_components.append(gr.Number(label=f\"Current Day's {col.replace('_', ' ').title()}\", value=1.0))\n",
        "\n",
        "\n",
        "# GRADIO INTERFACE SETUP\n",
        "iface = gr.Interface(\n",
        "    fn=predict_climate_simple,\n",
        "    inputs=input_components,\n",
        "    outputs=gr.Markdown(),\n",
        "    title=f\"Simplified Climate/Energy Price Prediction (Model: {MODEL.__class__.__name__})\",\n",
        "    description=\"This demo predicts energy prices using only current-day raw data and time features. This results in a cleaner interface but may slightly reduce model accuracy compared to the full time series model.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "UnzS900TBiJH",
        "outputId": "06c3f764-8593-487c-9721-ae478c488cec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplified Deployment Artifacts Loaded Successfully.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5a1bded7e0b186e510.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5a1bded7e0b186e510.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}